{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e1f8d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import librosa\n",
    "import pretty_midi\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8965e585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "data_dir = Path(\"spectrogram_data\")\n",
    "with open(data_dir / \"hmm_model.pkl\", 'rb') as f:\n",
    "    model_data = pickle.load(f)\n",
    "    hmm_model = model_data['model']\n",
    "    pca_model = model_data['pca_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6703d37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: d99f6dd9-8f68-4962-97ff-036a72051e5c.wav\n",
      "Spectrogram shape: (80, 1358)\n"
     ]
    }
   ],
   "source": [
    "# Load your WAV file\n",
    "wav_file = Path(\"/Users/jameswang/workspace/Pattern for Prediction audio to audio/hmm_beat_pattern/normalized_dataset/test/d99f6dd9-8f68-4962-97ff-036a72051e5c.wav\")  # Change this path\n",
    "y, sr = librosa.load(str(wav_file), sr=22050)\n",
    "\n",
    "# Extract mel spectrogram for the entire file\n",
    "S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=80, n_fft=2048, hop_length=512)\n",
    "mel_db = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "print(f\"Loaded: {wav_file.name}\")\n",
    "print(f\"Spectrogram shape: {mel_db.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "846c4bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted 148 spectrograms\n",
      "Shape: (148, 80, 10)\n"
     ]
    }
   ],
   "source": [
    "# Extract beat times\n",
    "_, beats = librosa.beat.beat_track(y=y, sr=sr)\n",
    "beat_times = librosa.frames_to_time(beats, sr=sr)\n",
    "\n",
    "# Create 16th-note spectrograms (10 time steps each)\n",
    "specs = []\n",
    "hop_length = 512\n",
    "\n",
    "for i in range(len(beat_times) - 1):\n",
    "    beat_start = beat_times[i]\n",
    "    beat_end = beat_times[i + 1]\n",
    "    beat_duration = beat_end - beat_start\n",
    "    \n",
    "    for j in range(4):  # 4 sixteenth notes per beat\n",
    "        sixteenth_start = beat_start + j * beat_duration / 4\n",
    "        sixteenth_end = beat_start + (j + 1) * beat_duration / 4\n",
    "        \n",
    "        start_frame = librosa.time_to_frames(sixteenth_start, sr=sr, hop_length=hop_length)\n",
    "        end_frame = librosa.time_to_frames(sixteenth_end, sr=sr, hop_length=hop_length)\n",
    "        \n",
    "        spec = mel_db[:, start_frame:end_frame]\n",
    "        \n",
    "        # Pad to 10 time steps\n",
    "        if spec.shape[1] < 10:\n",
    "            spec = np.pad(spec, ((0, 0), (0, 10 - spec.shape[1])), mode='constant')\n",
    "        else:\n",
    "            spec = spec[:, :10]\n",
    "        \n",
    "        specs.append(spec)\n",
    "        \n",
    "specs_array = np.array(specs)\n",
    "print(f\"✓ Extracted {len(specs)} spectrograms\")\n",
    "print(f\"Shape: {specs_array.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bda7692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Features shape: (148, 20)\n",
      "Reduced from 800D → 20D\n"
     ]
    }
   ],
   "source": [
    "# apply pca\n",
    "# Flatten spectrograms (80×10 → 800)\n",
    "specs_flat = specs_array.reshape(len(specs), -1)\n",
    "\n",
    "# Apply PCA to get 20D features\n",
    "features = pca_model.transform(specs_flat)\n",
    "\n",
    "print(f\"✓ Features shape: {features.shape}\")\n",
    "print(f\"Reduced from 800D → 20D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "887253ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden state path: [2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "Final state: 4\n"
     ]
    }
   ],
   "source": [
    "# Find hidden state path using Viterbi\n",
    "state_path = hmm_model.predict(features)\n",
    "final_state = state_path[-1]\n",
    "\n",
    "print(f\"Hidden state path: {state_path}\")\n",
    "print(f\"Final state: {final_state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27e84c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Generated 148 observations\n"
     ]
    }
   ],
   "source": [
    "# generate continuation\n",
    "# Sample from final state forward\n",
    "n_continuation = len(features)  # Same length as input\n",
    "generated = []\n",
    "current_state = final_state\n",
    "\n",
    "for _ in range(n_continuation):\n",
    "    # Get mean and covariance for current state\n",
    "    mean = hmm_model.means_[current_state].copy()\n",
    "    cov = hmm_model.covars_[current_state]\n",
    "    \n",
    "    # Handle both diagonal and full covariance\n",
    "    if cov.ndim == 1:\n",
    "        cov_matrix = np.diag(np.abs(cov) + 1e-6)\n",
    "    else:\n",
    "        cov_matrix = cov + np.eye(cov.shape[0]) * 1e-6\n",
    "    \n",
    "    # Sample observation\n",
    "    obs = np.random.multivariate_normal(mean, cov_matrix)\n",
    "    generated.append(obs)\n",
    "    \n",
    "    # Transition to next state\n",
    "    transition_probs = hmm_model.transmat_[current_state]\n",
    "    current_state = np.random.choice(len(transition_probs), p=transition_probs)\n",
    "\n",
    "continuation_features = np.array(generated)\n",
    "print(f\"✓ Generated {len(continuation_features)} observations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d70214d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Spectrograms shape: (148, 80, 10)\n"
     ]
    }
   ],
   "source": [
    "# inverse pca\n",
    "# Convert from 20D back to 800D\n",
    "continuation_specs_flat = pca_model.inverse_transform(continuation_features)\n",
    "\n",
    "# Reshape to 80×10\n",
    "continuation_specs = continuation_specs_flat.reshape(n_continuation, 80, 10)\n",
    "\n",
    "print(f\"✓ Spectrograms shape: {continuation_specs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd45307d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full mel spectrogram shape: (80, 1480)\n",
      "✓ Reconstructed audio shape: (757248,)\n",
      "✓ Duration: 34.34 seconds\n"
     ]
    }
   ],
   "source": [
    "# Reconstruct audio from mel spectrograms using Griffin-Lim\n",
    "\n",
    "sr = 22050\n",
    "n_mels = 80\n",
    "n_fft = 2048\n",
    "hop_length = 512\n",
    "\n",
    "# Concatenate all mel spectrograms into one long spectrogram\n",
    "# Stack along time axis\n",
    "mel_spec_full = np.concatenate(continuation_specs, axis=1)\n",
    "print(f\"Full mel spectrogram shape: {mel_spec_full.shape}\")\n",
    "\n",
    "# Convert from dB back to linear magnitude\n",
    "mel_spec_linear = librosa.db_to_power(mel_spec_full)\n",
    "\n",
    "# Convert mel spectrogram back to normal spectrogram\n",
    "spec = librosa.feature.inverse.mel_to_stft(mel_spec_linear, sr=sr, n_fft=n_fft)\n",
    "\n",
    "# Use Griffin-Lim to reconstruct phase and get waveform\n",
    "y = librosa.griffinlim(spec, hop_length=hop_length, n_iter=32)\n",
    "\n",
    "print(f\"✓ Reconstructed audio shape: {y.shape}\")\n",
    "print(f\"✓ Duration: {len(y) / sr:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6774a0cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "rate must be specified when data is a numpy array or list of audio samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Audio\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mAudio\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/p4p/lib/python3.12/site-packages/IPython/lib/display.py:130\u001b[39m, in \u001b[36mAudio.__init__\u001b[39m\u001b[34m(self, data, filename, url, embed, rate, autoplay, normalize, element_id)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.data, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[32m    129\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mrate must be specified when data is a numpy array or list of audio samples.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    131\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = Audio._make_wav(data, rate, normalize)\n",
      "\u001b[31mValueError\u001b[39m: rate must be specified when data is a numpy array or list of audio samples."
     ]
    }
   ],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f534576",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p4p",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
